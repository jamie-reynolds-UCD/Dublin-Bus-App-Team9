{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "divine-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import datetime as dt\n",
    "\n",
    "import pickle\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-queens",
   "metadata": {},
   "source": [
    "# Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tutorial-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "routeNum = '270'\n",
    "df = pd.read_csv(f'lines/{routeNum}/{routeNum}_MODELING.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "upper-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stop in stops_1:\n",
    "#     print(stop)\n",
    "#     workingDF = df[df['startStop']==stop]\n",
    "#     print(workingDF['endStop'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powered-western",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIRECTION             int64\n",
       "MONTH                 int64\n",
       "WEEKDAY               int64\n",
       "HOUR                  int64\n",
       "startStop             int64\n",
       "endStop             float64\n",
       "ARR_ACT               int64\n",
       "DEP_ACT               int64\n",
       "JOURNEYTIME           int64\n",
       "temp                float64\n",
       "humidity              int64\n",
       "wind_speed          float64\n",
       "precipitation_1h    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-nylon",
   "metadata": {},
   "source": [
    "### convert month, weekday, startStop, endStop to type category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arranged-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['MONTH', 'WEEKDAY', 'startStop', 'endStop']] =\\\n",
    "df[['MONTH', 'WEEKDAY', 'startStop', 'endStop']].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-fault",
   "metadata": {},
   "source": [
    "## Make copy of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "optional-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-lightweight",
   "metadata": {},
   "source": [
    "## Split the dataframe up by direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "essential-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev_1 = df_rev[df_rev['DIRECTION']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nonprofit-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev_2 = df_rev[df_rev['DIRECTION']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-bible",
   "metadata": {},
   "source": [
    "### generate a list of stops for each direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "northern-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_1 = sorted(list(df_rev_1['startStop'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "timely-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_2 = sorted(list(df_rev_2['startStop'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "treated-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stops_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-survivor",
   "metadata": {},
   "source": [
    "# Direction 1 first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-services",
   "metadata": {},
   "source": [
    "### For each stop, make a dataframe and split it into test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fluid-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/comp47350py38/lib/python3.8/site-packages/pandas/core/frame.py:4305: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Make dictionaries with keys for each stop with each train/test split value as its values.\n",
    "\n",
    "X_trainDict_1 = {}\n",
    "y_trainDict_1 = {}\n",
    "X_testDict_1 ={}\n",
    "y_testDict_1 = {}\n",
    "\n",
    "remove = []\n",
    "\n",
    "for stop in stops_1:\n",
    "    \n",
    "    workingDF = df_rev_1[df_rev_1['startStop']==stop]\n",
    "    \n",
    "    if workingDF.shape[0] < 3:\n",
    "        print(f'{stop} too small')\n",
    "        remove.append(stop)\n",
    "        continue\n",
    "    \n",
    "    # drop unnecessary columns\n",
    "    workingDF.drop(columns=['startStop', 'endStop', 'DIRECTION', 'DEP_ACT', 'ARR_ACT'], inplace=True)\n",
    "    \n",
    "    # y is the target\n",
    "    y = workingDF[\"JOURNEYTIME\"]\n",
    "    # X is everything else\n",
    "    X = workingDF.drop([\"JOURNEYTIME\"],1)\n",
    "    # Split the dataset into two datasets: 70% training and 30% test\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,  test_size=0.3)\n",
    "    \n",
    "    X_trainDict_1[stop] = X_train\n",
    "    X_testDict_1[stop] = X_test\n",
    "    y_trainDict_1[stop] = y_train\n",
    "    y_testDict_1[stop] = y_test\n",
    "    \n",
    "    # need to reset the index to allow contatenation with predicted values otherwise not joining on same index...\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "for i in remove:\n",
    "    stops_1.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-shelter",
   "metadata": {},
   "source": [
    "### For each stop, make a linReg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "essential-bookmark",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now modelling stop number 3328.\n",
      "Now modelling stop number 3329.\n",
      "Now modelling stop number 3330.\n",
      "Now modelling stop number 3331.\n",
      "Now modelling stop number 3332.\n",
      "Now modelling stop number 3351.\n",
      "Now modelling stop number 4323.\n",
      "Now modelling stop number 4324.\n",
      "Now modelling stop number 4325.\n",
      "Now modelling stop number 4765.\n",
      "Now modelling stop number 4766.\n",
      "Now modelling stop number 4767.\n",
      "Now modelling stop number 4768.\n",
      "Now modelling stop number 4769.\n",
      "Now modelling stop number 4770.\n",
      "Now modelling stop number 7026.\n"
     ]
    }
   ],
   "source": [
    "modelDict_1 = {}\n",
    "\n",
    "for stop in stops_1:\n",
    "    print(f'Now modelling stop number {stop}.')\n",
    "    \n",
    "    X_train = X_trainDict_1[stop]\n",
    "    X_test = X_testDict_1[stop]\n",
    "    y_train = y_trainDict_1[stop]\n",
    "    y_test = y_testDict_1[stop]\n",
    "    \n",
    "    linReg = LinearRegression().fit(X_train, y_train)\n",
    "    \n",
    "    modelDict_1[stop] = linReg\n",
    "    \n",
    "    endStop = int(df_rev_1[df_rev_1['startStop']==stop]['endStop'].mode())\n",
    "    \n",
    "    filename = f'lines/{routeNum}/{routeNum}_models/dir1/FROM_{stop}_TO_{endStop}.sav'\n",
    "    pickle.dump(linReg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-morning",
   "metadata": {},
   "source": [
    "### Evaluate model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lesser-sunglasses",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now modelling for stop number 3328.\n",
      "Now modelling for stop number 3329.\n",
      "Now modelling for stop number 3330.\n",
      "Now modelling for stop number 3331.\n",
      "Now modelling for stop number 3332.\n",
      "Now modelling for stop number 3351.\n",
      "Now modelling for stop number 4323.\n",
      "Now modelling for stop number 4324.\n",
      "Now modelling for stop number 4325.\n",
      "Now modelling for stop number 4765.\n",
      "Now modelling for stop number 4766.\n",
      "Now modelling for stop number 4767.\n",
      "Now modelling for stop number 4768.\n",
      "Now modelling for stop number 4769.\n",
      "Now modelling for stop number 4770.\n",
      "Now modelling for stop number 7026.\n"
     ]
    }
   ],
   "source": [
    "for stop in stops_1:  \n",
    "    X_train = X_trainDict_1[stop]\n",
    "    y_train = list(y_trainDict_1[stop])\n",
    "    linReg = modelDict_1[stop]\n",
    "    \n",
    "    print(f'Now modelling for stop number {stop}.')\n",
    "    \n",
    "    linReg_predictions_train = list(linReg.predict(X_train))\n",
    "    with open(f'lines/{routeNum}/{routeNum}_dir1_linReg_trainMetrics.csv', 'a') as fh:\n",
    "        fh.write('\\n\\n=============================================================================='+\\\n",
    "                f'\\nMetrics for stop model number {stop}:'\n",
    "                f'\\nMAE: {metrics.mean_absolute_error(y_train, linReg_predictions_train)}' +\\\n",
    "                f'\\nMAPE: {metrics.mean_absolute_percentage_error(y_train, linReg_predictions_train)}'+\\\n",
    "                f'\\nMSE: {metrics.mean_squared_error(y_train, linReg_predictions_train)}'+\\\n",
    "                f'\\nRMSE: {metrics.mean_squared_error(y_train, linReg_predictions_train)**(0.5)}'+\\\n",
    "                f'\\nR2: {metrics.r2_score(y_train, linReg_predictions_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-possible",
   "metadata": {},
   "source": [
    "### Evaluate model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "qualified-syndicate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now modelling for stop number 3328.\n",
      "Now modelling for stop number 3329.\n",
      "Now modelling for stop number 3330.\n",
      "Now modelling for stop number 3331.\n",
      "Now modelling for stop number 3332.\n",
      "Now modelling for stop number 3351.\n",
      "Now modelling for stop number 4323.\n",
      "Now modelling for stop number 4324.\n",
      "Now modelling for stop number 4325.\n",
      "Now modelling for stop number 4765.\n",
      "Now modelling for stop number 4766.\n",
      "Now modelling for stop number 4767.\n",
      "Now modelling for stop number 4768.\n",
      "Now modelling for stop number 4769.\n",
      "Now modelling for stop number 4770.\n",
      "Now modelling for stop number 7026.\n"
     ]
    }
   ],
   "source": [
    "for stop in stops_1:  \n",
    "    X_test = X_testDict_1[stop]\n",
    "    y_test = list(y_testDict_1[stop])\n",
    "    linReg = modelDict_1[stop]\n",
    "    \n",
    "    print(f'Now modelling for stop number {stop}.')\n",
    "    \n",
    "    linReg_predictions_test = list(linReg.predict(X_test))\n",
    "    \n",
    "    with open(f'lines/{routeNum}/{routeNum}_dir1_linReg_testMetrics.csv', 'a') as fh:\n",
    "        fh.write('\\n\\n=============================================================================='+\\\n",
    "                f'\\nMetrics for stop model number {stop}:'\n",
    "                f'\\nMAE: {metrics.mean_absolute_error(y_test, linReg_predictions_test)}' +\\\n",
    "                f'\\nMAPE: {metrics.mean_absolute_percentage_error(y_test, linReg_predictions_test)}'+\\\n",
    "                f'\\nMSE: {metrics.mean_squared_error(y_test, linReg_predictions_test)}'+\\\n",
    "                f'\\nRMSE: {metrics.mean_squared_error(y_test, linReg_predictions_test)**(0.5)}'+\\\n",
    "                f'\\nR2: {metrics.r2_score(y_test, linReg_predictions_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-interpretation",
   "metadata": {},
   "source": [
    "# Direction 2 next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-sailing",
   "metadata": {},
   "source": [
    "### For each stop, make a dataframe and split it into test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "numeric-sphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/comp47350py38/lib/python3.8/site-packages/pandas/core/frame.py:4305: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Make dictionaries with keys for each stop with each train/test split value as its values.\n",
    "\n",
    "X_trainDict_2 = {}\n",
    "y_trainDict_2 = {}\n",
    "X_testDict_2 ={}\n",
    "y_testDict_2 = {}\n",
    "\n",
    "remove = []\n",
    "\n",
    "for stop in stops_2:\n",
    "    workingDF = df_rev_2[df_rev_2['startStop']==stop]\n",
    "    \n",
    "    # drop unnecessary columns\n",
    "    workingDF.drop(columns=['startStop', 'endStop', 'DIRECTION', 'DEP_ACT', 'ARR_ACT'], inplace=True)\n",
    "    \n",
    "    if workingDF.shape[0] < 3:\n",
    "        print(f'{stop} too small')\n",
    "        remove.append(stop)\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "\n",
    "        # y is the target\n",
    "        y = workingDF[\"JOURNEYTIME\"]\n",
    "        # X is everything else\n",
    "        X = workingDF.drop([\"JOURNEYTIME\"],1)\n",
    "        # Split the dataset into two datasets: 70% training and 30% test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1,  test_size=0.3)\n",
    "\n",
    "        X_trainDict_2[stop] = X_train\n",
    "        X_testDict_2[stop] = X_test\n",
    "        y_trainDict_2[stop] = y_train\n",
    "        y_testDict_2[stop] = y_test\n",
    "\n",
    "        # need to reset the index to allow contatenation with predicted values otherwise not joining on same index...\n",
    "        X_train.reset_index(drop=True, inplace=True)\n",
    "        y_train.reset_index(drop=True, inplace=True)\n",
    "        X_test.reset_index(drop=True, inplace=True)\n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "for i in remove:\n",
    "    stops_2.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-scientist",
   "metadata": {},
   "source": [
    "### For each stop, make a linReg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "satellite-cabin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now modelling stop number 3333.\n",
      "Now modelling stop number 3334.\n",
      "Now modelling stop number 3335.\n",
      "Now modelling stop number 3336.\n",
      "Now modelling stop number 3337.\n",
      "Now modelling stop number 3338.\n",
      "Now modelling stop number 3339.\n",
      "Now modelling stop number 3340.\n",
      "Now modelling stop number 3352.\n",
      "Now modelling stop number 4324.\n",
      "Now modelling stop number 4326.\n",
      "Now modelling stop number 4765.\n",
      "Now modelling stop number 4766.\n",
      "Now modelling stop number 4767.\n",
      "Now modelling stop number 4768.\n",
      "Now modelling stop number 4769.\n",
      "Now modelling stop number 4770.\n"
     ]
    }
   ],
   "source": [
    "modelDict_2 = {}\n",
    "\n",
    "for stop in stops_2:\n",
    "    print(f'Now modelling stop number {stop}.')\n",
    "    \n",
    "    X_train = X_trainDict_2[stop]\n",
    "    X_test = X_testDict_2[stop]\n",
    "    y_train = y_trainDict_2[stop]\n",
    "    y_test = y_testDict_2[stop]\n",
    "    \n",
    "    linReg = LinearRegression().fit(X_train, y_train)\n",
    "    \n",
    "    modelDict_2[stop] = linReg\n",
    "    \n",
    "    endStop = int(df_rev_2[df_rev_2['startStop']==stop]['endStop'].mode())\n",
    "    \n",
    "    filename = f'lines/{routeNum}/{routeNum}_models/dir2/FROM_{stop}_TO_{endStop}.sav'\n",
    "    pickle.dump(linReg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-insert",
   "metadata": {},
   "source": [
    "### Evaluate model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "swedish-chest",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now modelling for stop number 3333.\n",
      "Now modelling for stop number 3334.\n",
      "Now modelling for stop number 3335.\n",
      "Now modelling for stop number 3336.\n",
      "Now modelling for stop number 3337.\n",
      "Now modelling for stop number 3338.\n",
      "Now modelling for stop number 3339.\n",
      "Now modelling for stop number 3340.\n",
      "Now modelling for stop number 3352.\n",
      "Now modelling for stop number 4324.\n",
      "Now modelling for stop number 4326.\n",
      "Now modelling for stop number 4765.\n",
      "Now modelling for stop number 4766.\n",
      "Now modelling for stop number 4767.\n",
      "Now modelling for stop number 4768.\n",
      "Now modelling for stop number 4769.\n",
      "Now modelling for stop number 4770.\n"
     ]
    }
   ],
   "source": [
    "for stop in stops_2:  \n",
    "    X_train = X_trainDict_2[stop]\n",
    "    y_train = list(y_trainDict_2[stop])\n",
    "    linReg = modelDict_2[stop]\n",
    "    \n",
    "    print(f'Now modelling for stop number {stop}.')\n",
    "    \n",
    "    linReg_predictions_train = list(linReg.predict(X_train))\n",
    "    with open(f'lines/{routeNum}/{routeNum}_dir2_linReg_trainMetrics.csv', 'a') as fh:\n",
    "        fh.write('\\n\\n=============================================================================='+\\\n",
    "                f'\\nMetrics for stop model number {stop}:'\n",
    "                f'\\nMAE: {metrics.mean_absolute_error(y_train, linReg_predictions_train)}' +\\\n",
    "                f'\\nMAPE: {metrics.mean_absolute_percentage_error(y_train, linReg_predictions_train)}'+\\\n",
    "                f'\\nMSE: {metrics.mean_squared_error(y_train, linReg_predictions_train)}'+\\\n",
    "                f'\\nRMSE: {metrics.mean_squared_error(y_train, linReg_predictions_train)**(0.5)}'+\\\n",
    "                f'\\nR2: {metrics.r2_score(y_train, linReg_predictions_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-bleeding",
   "metadata": {},
   "source": [
    "### Evaluate model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spread-advisory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now modelling for stop number 3333.\n",
      "Now modelling for stop number 3334.\n",
      "Now modelling for stop number 3335.\n",
      "Now modelling for stop number 3336.\n",
      "Now modelling for stop number 3337.\n",
      "Now modelling for stop number 3338.\n",
      "Now modelling for stop number 3339.\n",
      "Now modelling for stop number 3340.\n",
      "Now modelling for stop number 3352.\n",
      "Now modelling for stop number 4324.\n",
      "Now modelling for stop number 4326.\n",
      "Now modelling for stop number 4765.\n",
      "Now modelling for stop number 4766.\n",
      "Now modelling for stop number 4767.\n",
      "Now modelling for stop number 4768.\n",
      "Now modelling for stop number 4769.\n",
      "Now modelling for stop number 4770.\n"
     ]
    }
   ],
   "source": [
    "for stop in stops_2:  \n",
    "    X_test = X_testDict_2[stop]\n",
    "    y_test = list(y_testDict_2[stop])\n",
    "    linReg = modelDict_2[stop]\n",
    "    \n",
    "    print(f'Now modelling for stop number {stop}.')\n",
    "    \n",
    "    linReg_predictions_test = list(linReg.predict(X_test))\n",
    "    \n",
    "    with open(f'lines/{routeNum}/{routeNum}_dir2_linReg_testMetrics.csv', 'a') as fh:\n",
    "        fh.write('\\n\\n=============================================================================='+\\\n",
    "                f'\\nMetrics for stop model number {stop}:'\n",
    "                f'\\nMAE: {metrics.mean_absolute_error(y_test, linReg_predictions_test)}' +\\\n",
    "                f'\\nMAPE: {metrics.mean_absolute_percentage_error(y_test, linReg_predictions_test)}'+\\\n",
    "                f'\\nMSE: {metrics.mean_squared_error(y_test, linReg_predictions_test)}'+\\\n",
    "                f'\\nRMSE: {metrics.mean_squared_error(y_test, linReg_predictions_test)**(0.5)}'+\\\n",
    "                f'\\nR2: {metrics.r2_score(y_test, linReg_predictions_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-friend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-spray",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
